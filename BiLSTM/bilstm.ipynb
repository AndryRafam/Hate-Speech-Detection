{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8237874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c8a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt as a woman you shouldn complain about cleaning up your house amp as a man you should always take the trash out', 'rt boy dats cold tyga dwn bad for cuffin dat hoe in the place', 'rt dawg rt you ever fuck a bitch and she start to cry you be confused as shit', 'rt she look like a tranny', 'rt the shit you hear about me might be true or it might be faker than the bitch who told it to ya']\n",
      "[[    0     0     0 ...     5    49    55]\n",
      " [    0     0     0 ...    12     5   511]\n",
      " [    0     0     0 ...  1039    72    45]\n",
      " ...\n",
      " [    0     0     0 ...   341    28   269]\n",
      " [    0     0     0 ...  1800     6  1296]\n",
      " [    0     0     0 ...   115     2 18599]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,758,019\n",
      "Trainable params: 2,758,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "436/436 [==============================] - 24s 46ms/step - loss: 0.3996 - accuracy: 0.8602 - val_loss: 0.3063 - val_accuracy: 0.8900\n",
      "Epoch 2/5\n",
      "436/436 [==============================] - 19s 44ms/step - loss: 0.2197 - accuracy: 0.9255 - val_loss: 0.3030 - val_accuracy: 0.8855\n",
      "Epoch 3/5\n",
      "436/436 [==============================] - 19s 44ms/step - loss: 0.1378 - accuracy: 0.9535 - val_loss: 0.3563 - val_accuracy: 0.8797\n",
      "Epoch 4/5\n",
      "436/436 [==============================] - 20s 45ms/step - loss: 0.0897 - accuracy: 0.9684 - val_loss: 0.4551 - val_accuracy: 0.8621\n",
      "Epoch 5/5\n",
      "436/436 [==============================] - 19s 44ms/step - loss: 0.0676 - accuracy: 0.9774 - val_loss: 0.4987 - val_accuracy: 0.8597\n",
      "194/194 [==============================] - 3s 13ms/step - loss: 0.3079 - accuracy: 0.8901\n",
      "\n",
      "Test acc: 89.01 %\n",
      "Test loss: 30.79 %\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class Hate_Speech():\n",
    "\t\n",
    "\tdef unzip(self,nm):\n",
    "\t\twith ZipFile(nm,\"r\") as zip:\n",
    "\t\t\tzip.extractall()\n",
    "\n",
    "\tdef preprocess(self,y):\n",
    "\t\tself.x = y.lower()\n",
    "\t\tself.x = self.x.encode(\"ascii\",\"ignore\").decode()\n",
    "\t\tself.x = re.sub(\"https*\\S+\",\" \",self.x)\n",
    "\t\tself.x = re.sub(\"@\\S+\",\" \",self.x)\n",
    "\t\tself.x = re.sub(\"#\\S+\",\" \",self.x)\n",
    "\t\tself.x = re.sub(\"\\'\\w+\",\"\",self.x)\n",
    "\t\tself.x = re.sub(\"[%s]\" % re.escape(string.punctuation),\" \", self.x)\n",
    "\t\tself.x = re.sub(\"\\w*\\d+\\w*\",\"\",self.x)\n",
    "\t\tself.x = re.sub(\"\\s{2,}\",\" \",self.x)\n",
    "\t\treturn self.x\n",
    "\n",
    "\tdef tokenize(self,y):\n",
    "\t\tfor self.x in y:\n",
    "\t\t\tyield(word_tokenize(str(self.x)))\n",
    "\n",
    "\tdef detokenize(self,txt):\n",
    "\t\treturn TreebankWordDetokenizer().detokenize(txt)\n",
    "\n",
    "\tdef model(self,inputs):\n",
    "\t\tself.x = Embedding(max_words,128)(inputs)\n",
    "\t\tself.x = Bidirectional(LSTM(64,return_sequences=True))(self.x)\n",
    "\t\tself.x = Bidirectional(LSTM(64))(self.x)\n",
    "\t\tself.outputs = Dense(3,activation=\"softmax\")(self.x)\n",
    "\t\tself.model = Model(inputs,self.outputs)\n",
    "\t\treturn self.model\n",
    "\n",
    "ht = Hate_Speech()\n",
    "\t\n",
    "ht.unzip(\"archive.zip\")\n",
    "df = pd.read_csv(\"hate_speech.csv\")\n",
    "temp = []\n",
    "data_to_list = df[\"tweet\"].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "\ttemp.append(ht.preprocess(data_to_list[i]))\n",
    "\t\t\t\n",
    "data_words = list(ht.tokenize(temp))\n",
    "\t\n",
    "final_data = []\n",
    "for i in range(len(data_words)):\n",
    "\tfinal_data.append(ht.detokenize(data_words[i]))\n",
    "print(final_data[:5])\n",
    "final_data = np.array(final_data)\n",
    "\n",
    "max_words = 20000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(final_data)\n",
    "sequences = tokenizer.texts_to_sequences(final_data)\n",
    "tweets = pad_sequences(sequences,maxlen=max_len)\n",
    "with open(\"tokenizer.pickle\",\"wb\") as handle:\n",
    "\tpickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(tweets)\n",
    "\n",
    "labels = df[\"class\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(tweets,labels,random_state=42)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.25,random_state=42)\n",
    "\n",
    "model = ht.model(Input(shape=(None,),dtype=\"int32\"))\n",
    "model.summary()\n",
    "model.compile(Adam(),SparseCategoricalCrossentropy(),metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"hate_speech.h5\",monitor=\"val_accuracy\",save_best_only=True,save_weights_only=False)\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=5,validation_data=(x_val,y_val),callbacks=[checkpoint])\n",
    "best = load_model(\"hate_speech.h5\")\n",
    "loss,acc = best.evaluate(x_test,y_test)\n",
    "print(\"\\nTest acc: {:.2f} %\".format(100*acc))\n",
    "print(\"Test loss: {:.2f} %\".format(100*loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e145e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d828f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
