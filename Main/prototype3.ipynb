{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342385cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c2066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0            0      3            0                   0        3      2   \n",
      "1            1      3            0                   3        0      1   \n",
      "2            2      3            0                   3        0      1   \n",
      "3            3      3            0                   2        1      1   \n",
      "4            4      6            0                   6        0      1   \n",
      "5            5      3            1                   2        0      1   \n",
      "6            6      3            0                   3        0      1   \n",
      "7            7      3            0                   3        0      1   \n",
      "8            8      3            0                   3        0      1   \n",
      "9            9      3            1                   2        0      1   \n",
      "10          10      3            0                   3        0      1   \n",
      "11          11      3            0                   3        0      1   \n",
      "12          12      3            0                   2        1      1   \n",
      "13          13      3            0                   3        0      1   \n",
      "14          14      3            1                   2        0      1   \n",
      "\n",
      "                                                tweet  \n",
      "0   !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1   !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2   !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3   !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4   !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
      "5   !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...  \n",
      "6   !!!!!!\"@__BrighterDays: I can not just sit up ...  \n",
      "7   !!!!&#8220;@selfiequeenbri: cause I'm tired of...  \n",
      "8   \" &amp; you might not get ya bitch back &amp; ...  \n",
      "9   \" @rhythmixx_ :hobbies include: fighting Maria...  \n",
      "10  \" Keeks is a bitch she curves everyone \" lol I...  \n",
      "11                 \" Murda Gang bitch its Gang Land \"  \n",
      "12  \" So hoes that smoke are losers ? \" yea ... go...  \n",
      "13      \" bad bitches is the only thing that i like \"  \n",
      "14                            \" bitch get up off me \"  \n",
      "24783\n",
      "       Unnamed: 0  count  hate_speech  offensive_language  neither  tweet\n",
      "class                                                                    \n",
      "0            1430      5            6                   5        5   1430\n",
      "1           19190      5            5                   8        4  19190\n",
      "2            4163      5            4                   5        8   4163\n",
      "                                               tweet  class\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../Data/data.csv\")\n",
    "print(train.head(15))\n",
    "print(len(train))\n",
    "print(train.groupby('class').nunique())\n",
    "train = train[['tweet','class']]\n",
    "print(train.head())\n",
    "print(train['tweet'].isnull().sum())\n",
    "stop_words = stopwords.words(\"english\")\n",
    "wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727c9c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' rt woman complain cleaning house amp man always take trash out ', ' rt boy dats cold tyga dwn bad cuffin dat hoe place ', ' rt dawg rt ever fuck bitch start cry confused shit', ' rt look like tranny', ' rt shit hear might true might faker bitch told ya ']\n",
      "24783\n"
     ]
    }
   ],
   "source": [
    "# Data processing\n",
    "def text_preproc(x):\n",
    "\tx = x.lower()\n",
    "\tx = \" \".join([word for word in x.split(\" \") if word not in stop_words])\n",
    "\tx = x.encode(\"ascii\", \"ignore\").decode()\n",
    "\tx = re.sub(r\"https*\\S+\", \" \", x)\n",
    "\tx = re.sub(r\"@\\S+\", \" \", x)\n",
    "\tx = re.sub(r\"#\\S+\", \" \", x)\n",
    "\tx = re.sub(r\"\\\",\\w+\", \"\", x)\n",
    "\tx = re.sub(\"[%s]\" % re.escape(string.punctuation), \" \", x)\n",
    "\tx = re.sub(r\"\\w*\\d+\\w*\", \"\", x)\n",
    "\tx = re.sub(r\"\\s{2,}\", \" \", x)\n",
    "\treturn x\n",
    "\t\n",
    "final_data = []\n",
    "data_to_list = train[\"tweet\"].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "\tfinal_data.append(text_preproc(data_to_list[i]))\n",
    "print(list(final_data[:5]))\n",
    "\n",
    "final_data = np.array(final_data)\n",
    "\n",
    "labels = np.array(train[\"class\"])\n",
    "labels = tf.keras.utils.to_categorical(labels,3,dtype=\"int32\")\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f2b2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sequencing and Splitting\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2990ddfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   86   19  281]\n",
      " [   0    0    0 ...   88    8  440]\n",
      " [   0    0    0 ...  502  972   17]\n",
      " ...\n",
      " [   0    0    0 ...  108  105  269]\n",
      " [   0    0    0 ...    3 1747 1233]\n",
      " [   0    0    0 ...  109   21   63]]\n",
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " ...\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "13940 4647 6196 13940 4647 6196\n"
     ]
    }
   ],
   "source": [
    "max_words = 5000 # Consider only the top 5k words\n",
    "max_len = 200 # Consider only the 200 first word of each tweet\n",
    "\n",
    "tokenizer3 = Tokenizer(num_words=max_words)\n",
    "tokenizer3.fit_on_texts(final_data)\n",
    "sequences = tokenizer3.texts_to_sequences(final_data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "with open('tockenizer3.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer3,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(tweets)\n",
    "print(labels)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tweets,labels,random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "print(len(x_train),len(x_val),len(x_test),len(y_train),len(y_val),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d57431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "436/436 [==============================] - 21s 39ms/step - loss: 0.3969 - accuracy: 0.8595 - val_loss: 0.3244 - val_accuracy: 0.8862\n",
      "Epoch 2/4\n",
      "436/436 [==============================] - 16s 37ms/step - loss: 0.2723 - accuracy: 0.9081 - val_loss: 0.2934 - val_accuracy: 0.8999\n",
      "Epoch 3/4\n",
      "436/436 [==============================] - 16s 37ms/step - loss: 0.2358 - accuracy: 0.9179 - val_loss: 0.2905 - val_accuracy: 0.8956\n",
      "Epoch 4/4\n",
      "325/436 [=====================>........] - ETA: 3s - loss: 0.2121 - accuracy: 0.9261"
     ]
    }
   ],
   "source": [
    "# Building and train NN\n",
    "## BiDR LST LAYER MODEL\n",
    "model = Sequential([\n",
    "    layers.Embedding(max_words,128,input_length=max_len),\n",
    "    layers.Bidirectional(layers.LSTM(64,return_sequences=True)),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.Dense(3,activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "checkpoint = ModelCheckpoint(\"../Model/best_model3.hdf5\", save_best_only=True, save_weights_only=False)\n",
    "history = model.fit(x_train, y_train, epochs=4, validation_data=(x_val,y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c5505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on X_test\n",
    "best_model = tf.keras.models.load_model(\"../Model/best_model3.hdf5\")\n",
    "test_loss, test_acc = best_model.evaluate(x_test,y_test,verbose=2)\n",
    "print(\"Test accuracy: {:.2f}%\".format(100*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f03688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
